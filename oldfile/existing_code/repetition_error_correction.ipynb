{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the google datasets cause they come with two values tuple instead of value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_file_list = os.listdir(\"C:/Users/matheus/Desktop/visual_literacy_of_ai_models/google_multi_answers_from_official_plots_with_no_faults8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['google_multi_answers_file_101_to_110.csv',\n",
       " 'google_multi_answers_file_111_to_120.csv',\n",
       " 'google_multi_answers_file_121_to_130.csv',\n",
       " 'google_multi_answers_file_131_to_140.csv',\n",
       " 'google_multi_answers_file_141_to_150.csv',\n",
       " 'google_multi_answers_file_151_to_160.csv',\n",
       " 'google_multi_answers_file_161_to_170.csv',\n",
       " 'google_multi_answers_file_171_to_180.csv',\n",
       " 'google_multi_answers_file_181_to_190.csv',\n",
       " 'google_multi_answers_file_191_to_200.csv',\n",
       " 'google_multi_answers_file_201_to_210.csv',\n",
       " 'google_multi_answers_file_211_to_220.csv',\n",
       " 'google_multi_answers_file_221_to_230.csv',\n",
       " 'google_multi_answers_file_231_to_240.csv',\n",
       " 'google_multi_answers_file_241_to_250.csv',\n",
       " 'google_multi_answers_file_251_to_260.csv',\n",
       " 'google_multi_answers_file_261_to_270.csv',\n",
       " 'google_multi_answers_file_271_to_280.csv',\n",
       " 'google_multi_answers_file_281_to_290.csv',\n",
       " 'google_multi_answers_file_291_to_300.csv',\n",
       " 'google_multi_answers_file_301_to_310.csv',\n",
       " 'google_multi_answers_file_311_to_320.csv',\n",
       " 'google_multi_answers_file_321_to_330.csv',\n",
       " 'google_multi_answers_file_331_to_340.csv',\n",
       " 'google_multi_answers_file_341_to_350.csv',\n",
       " 'google_multi_answers_file_351_to_360.csv',\n",
       " 'google_multi_answers_file_361_to_370.csv',\n",
       " 'google_multi_answers_file_371_to_380.csv']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"C:/Users/matheus/Desktop/visual_literacy_of_ai_models/google_multi_answers_from_official_plots_with_no_faults8/\"\n",
    "            +google_file_list[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_files_in_directory(directory):\n",
    "    all_dfs = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        if os.path.isfile(filepath):\n",
    "            try:\n",
    "                df = pd.read_csv(filepath)  # Adjust if using another format like .parquet\n",
    "                all_dfs.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {filename}: {e}\")\n",
    "    \n",
    "    if all_dfs:\n",
    "        return pd.concat(all_dfs, ignore_index=True)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tally_image_column(df):\n",
    "    if 'image' in df.columns:\n",
    "        return df['image'].value_counts()\n",
    "    else:\n",
    "        raise ValueError(\"Column 'image' not found in dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = stack_files_in_directory(\"C:/Users/matheus/Desktop/visual_literacy_of_ai_models/google_multi_answers_from_official_plots_with_no_faults8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt = stack_files_in_directory(\"C:/Users/matheus/Desktop/visual_literacy_of_ai_models/gpt_multi_answers_from_test8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = tally_image_column(df_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a = pd.DataFrame(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"thefile.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so first, lets check how many answers we got for each question, so we downsample to the same basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_df_perfect_plot = stack_files_in_directory(\"C:/Users/matheus/Desktop/visual_literacy_of_ai_models/google_multi_answers_from_official_plots_with_no_faults8\")\n",
    "df = google_df_perfect_plot\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(df[['image', 'question']].values, columns=['File', 'Question'])\n",
    "\n",
    "# Get unique combinations of 'File' and 'Question'\n",
    "unique_combinations = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matheus\\AppData\\Local\\Temp\\ipykernel_39388\\3896576606.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  value_column1 = row[0]  # First column: image\n",
      "C:\\Users\\matheus\\AppData\\Local\\Temp\\ipykernel_39388\\3896576606.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  value_column2 = row[1]  # Second column: question\n"
     ]
    }
   ],
   "source": [
    "for index, row in unique_combinations.iterrows():\n",
    "    value_column1 = row[0]  # First column: image\n",
    "    value_column2 = row[1]  # Second column: question\n",
    "    filtered_df = google_df_perfect_plot[(google_df_perfect_plot['image'] == value_column1) & (google_df_perfect_plot['question'] == value_column2)] \n",
    "    filtered_df.to_csv(f\"each_viz/{value_column1}__{index}.csv\")\n",
    "    #print(f\"Row {index} -> Column1: {value_column1}, Column2: {value_column2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_rows = []\n",
    "for i in os.listdir(\"each_vizGPT\"):\n",
    "    data = pd.read_csv(f\"each_vizGPT/{i}\") #get the data from that\n",
    "    sampled_rows.append(data.sample(1))\n",
    "\n",
    "#generate a single df\n",
    "result_df = pd.concat(sampled_rows, ignore_index=True)\n",
    "result_df.to_csv(\"resultingGPTPerfectPlotsDF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81900"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readydata = pd.read_csv(\"resultingGooglePerfectPlotsDF.csv\")\n",
    "readydata.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the gpt case is a little more complex because we have to think of the histograms that were forgotten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the gpt answers for histogram is actually perfect so all i need to do might be to just get the same thing and append them - and then i have to run some form of test to guarantee that each question appears the expected amount of times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matheus\\AppData\\Local\\Temp\\ipykernel_90232\\376829695.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  value_column1 = row[0]  # First column: image\n",
      "C:\\Users\\matheus\\AppData\\Local\\Temp\\ipykernel_90232\\376829695.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  value_column2 = row[1]  # Second column: question\n"
     ]
    }
   ],
   "source": [
    "gpt_df_perfect_plot = stack_files_in_directory(\"C:/Users/matheus/Desktop/visual_literacy_of_ai_models/gpt_multi_answers_from_official_plots_with_no_faults8\")\n",
    "df = gpt_df_perfect_plot #this is all of them together\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(df[['image', 'question']].values, columns=['File', 'Question'])\n",
    "\n",
    "# Get unique combinations of 'File' and 'Question'\n",
    "unique_combinations = df.drop_duplicates()\n",
    "\n",
    "for index, row in unique_combinations.iterrows():\n",
    "    value_column1 = row[0]  # First column: image\n",
    "    value_column2 = row[1]  # Second column: question\n",
    "    filtered_df = gpt_df_perfect_plot[(gpt_df_perfect_plot['image'] == value_column1) & (gpt_df_perfect_plot['question'] == value_column2)] \n",
    "    filtered_df.to_csv(f\"each_vizGPT/{value_column1}__{index}.csv\")\n",
    "    #print(f\"Row {index} -> Column1: {value_column1}, Column2: {value_column2}\")\n",
    "\n",
    "sampled_rows = []\n",
    "for i in os.listdir(\"each_vizGPT\"):\n",
    "    data = pd.read_csv(f\"each_vizGPT/{i}\") #get the data from that\n",
    "    sampled_rows.append(data.sample(1))\n",
    "\n",
    "#generate a single df\n",
    "result_df = pd.concat(sampled_rows, ignore_index=True)\n",
    "\n",
    "hist_answers = pd.read_csv(\"gpt_answers_for_histogram.csv\")\n",
    "\n",
    "stacked_df = pd.concat([result_df, hist_answers], ignore_index=True)  # Resets index\n",
    "\n",
    "#need to stack the hist answers under them\n",
    "stacked_df.to_csv(\"resultingGPTPerfectPlotsDF.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the same stuff but with the wrongaxis ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jï¿½ existe uma subpasta ou um arquivo each_vizGPTtest8.\n",
      "C:\\Users\\matheus\\AppData\\Local\\Temp\\ipykernel_90232\\1428325076.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  value_column1 = row[0]  # First column: image\n",
      "C:\\Users\\matheus\\AppData\\Local\\Temp\\ipykernel_90232\\1428325076.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  value_column2 = row[1]  # Second column: question\n"
     ]
    }
   ],
   "source": [
    "!mkdir \"each_vizGPTtest8\"\n",
    "gpt_df_perfect_plot = stack_files_in_directory(\"C:/Users/matheus/Desktop/visual_literacy_of_ai_models/gpt_multi_answers_from_test8\")\n",
    "df = gpt_df_perfect_plot #this is all of them together\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(df[['image', 'question']].values, columns=['File', 'Question'])\n",
    "\n",
    "# Get unique combinations of 'File' and 'Question'\n",
    "unique_combinations = df.drop_duplicates()\n",
    "\n",
    "for index, row in unique_combinations.iterrows():\n",
    "    value_column1 = row[0]  # First column: image\n",
    "    value_column2 = row[1]  # Second column: question\n",
    "    filtered_df = gpt_df_perfect_plot[(gpt_df_perfect_plot['image'] == value_column1) & (gpt_df_perfect_plot['question'] == value_column2)] \n",
    "    filtered_df.to_csv(f\"each_vizGPTtest8/{value_column1}__{index}.csv\")\n",
    "    #print(f\"Row {index} -> Column1: {value_column1}, Column2: {value_column2}\")\n",
    "\n",
    "sampled_rows = []\n",
    "for i in os.listdir(\"each_vizGPTtest8\"):\n",
    "    data = pd.read_csv(f\"each_vizGPTtest8/{i}\") #get the data from that\n",
    "    sampled_rows.append(data.sample(1))\n",
    "\n",
    "#generate a single df\n",
    "result_df = pd.concat(sampled_rows, ignore_index=True)\n",
    "\n",
    "#hist_answers = pd.read_csv(\"gpt_answers_for_histogram.csv\")\n",
    "\n",
    "#stacked_df = pd.concat([result_df, hist_answers], ignore_index=True)  # Resets index\n",
    "\n",
    "#need to stack the hist answers under them\n",
    "result_df.to_csv(\"resultingGPTMessedUpAxisPlotsDF.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the google ones with the messed up axis as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matheus\\AppData\\Local\\Temp\\ipykernel_90232\\253955608.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  value_column1 = row[0]  # First column: image\n",
      "C:\\Users\\matheus\\AppData\\Local\\Temp\\ipykernel_90232\\253955608.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  value_column2 = row[1]  # Second column: question\n"
     ]
    }
   ],
   "source": [
    "!mkdir \"each_vizGoogletest8\"\n",
    "gpt_df_perfect_plot = stack_files_in_directory(\"C:/Users/matheus/Desktop/visual_literacy_of_ai_models/google_multi_answers_from_test8\")\n",
    "df = gpt_df_perfect_plot #this is all of them together\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(df[['image', 'question']].values, columns=['File', 'Question'])\n",
    "\n",
    "# Get unique combinations of 'File' and 'Question'\n",
    "unique_combinations = df.drop_duplicates()\n",
    "\n",
    "for index, row in unique_combinations.iterrows():\n",
    "    value_column1 = row[0]  # First column: image\n",
    "    value_column2 = row[1]  # Second column: question\n",
    "    filtered_df = gpt_df_perfect_plot[(gpt_df_perfect_plot['image'] == value_column1) & (gpt_df_perfect_plot['question'] == value_column2)] \n",
    "    filtered_df.to_csv(f\"each_vizGoogletest8/{value_column1}__{index}.csv\")\n",
    "    #print(f\"Row {index} -> Column1: {value_column1}, Column2: {value_column2}\")\n",
    "\n",
    "sampled_rows = []\n",
    "for i in os.listdir(\"each_vizGoogletest8\"):\n",
    "    data = pd.read_csv(f\"each_vizGoogletest8/{i}\") #get the data from that\n",
    "    sampled_rows.append(data.sample(1))\n",
    "\n",
    "#generate a single df\n",
    "result_df = pd.concat(sampled_rows, ignore_index=True)\n",
    "\n",
    "#hist_answers = pd.read_csv(\"gpt_answers_for_histogram.csv\")\n",
    "\n",
    "#stacked_df = pd.concat([result_df, hist_answers], ignore_index=True)  # Resets index\n",
    "\n",
    "#need to stack the hist answers under them\n",
    "result_df.to_csv(\"resultingGoogleMessedUpAxisPlotsDF.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i have to redo the histograms for the test8 gpt - DONE FOR GPT, GOOGLE HAD ISSUES IN THE LAST ONES BUT NOW ITS RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(\"resultingGPTPerfectPlotsDF.csv\") - THIS ONE IS SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and also i need to open both of the google ones, fix that weird thing that has parenthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"resultingGooglePerfectPlotsDF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import ast\n",
    "# Function to convert string tuples to actual tuples and extract the first element\n",
    "def extract_first_element(value):\n",
    "    if isinstance(value, str) and value.startswith(\"(\") and value.endswith(\")\"):\n",
    "        try:\n",
    "            value = ast.literal_eval(value)  # Convert string to actual tuple\n",
    "        except (SyntaxError, ValueError):\n",
    "            return value  # If conversion fails, return original value\n",
    "    return value[0] if isinstance(value, tuple) else value\n",
    "\n",
    "# Apply to all elements in the DataFrame\n",
    "df = df.applymap(extract_first_element)'''\n",
    "\n",
    "import ast\n",
    "\n",
    "def extract_first_element(value):\n",
    "    if isinstance(value, str) and value.startswith(\"(\") and value.endswith(\")\"):\n",
    "        try:\n",
    "            value = ast.literal_eval(value)  # Convert string to tuple if possible\n",
    "        except (SyntaxError, ValueError):\n",
    "            pass  # If it fails, keep the original value\n",
    "    return value[0] if isinstance(value, tuple) else value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for some reason we also need this second function, cause the first one is coming out with True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_value(value):\n",
    "    if isinstance(value, str) and value.endswith(\" True\"):\n",
    "        return value.rsplit(\" \", 1)[0]  # Remove the last part after the last space\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matheus\\AppData\\Local\\Temp\\ipykernel_108948\\2079288042.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(extract_first_element)\n",
      "C:\\Users\\matheus\\AppData\\Local\\Temp\\ipykernel_108948\\2079288042.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(clean_value)\n"
     ]
    }
   ],
   "source": [
    "#df = df.applymap(lambda x: x[0] if isinstance(x, tuple) else x)\n",
    "df = df.applymap(extract_first_element)\n",
    "df = df.applymap(clean_value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"tocheck.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_1818_df = df.iloc[[1818]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1818    $13 - $24.2 True \n",
       "Name: gpt_answer_1, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_1818_df[\"gpt_answer_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok so there was a small mistake in which two questions were put together accidentally, and we need to run those two again for everyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_two_questions(dataframe):\n",
    "    predicate = dataframe[\"question\"] == \"What is the cost range of a sandwich in the cities? Options: $0 - $24.2, $0 - $55.9, $13 - $24.2, $17 - $35.2 The cost of vodka\"\n",
    "    dataframe = dataframe[~predicate]  # Keep rows where predicate is False\n",
    "    return dataframe\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to take test8 out so i can get the amelia rows from there\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecting data in test8.csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "googletest8 = pd.read_csv(\"C:/Users/matheus/Desktop/visual_literacy_of_ai_models/finalRESULTSDATASETS/google_test8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "openaitest8 = pd.read_csv(\"C:/Users/matheus/Desktop/visual_literacy_of_ai_models/finalRESULTSDATASETS/gpt_test8.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "googletest8.drop(['response_time_1', 'response_time_2',\n",
    "       'response_time_3', 'response_time_4', 'response_time_5',\n",
    "       'response_time_6', 'response_time_7', 'response_time_8',\n",
    "       'response_time_9', 'response_time_10', 'response_time_11',\n",
    "       'response_time_12', 'response_time_13', 'response_time_14',\n",
    "       'response_time_15', 'response_time_16', 'response_time_17',\n",
    "       'response_time_18', 'response_time_19', 'response_time_20', 'Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'dataset', 'image', 'question', 'gpt_answer_1',\n",
       "       'gpt_answer_2', 'gpt_answer_3', 'gpt_answer_4', 'gpt_answer_5',\n",
       "       'gpt_answer_6', 'gpt_answer_7', 'gpt_answer_8', 'gpt_answer_9',\n",
       "       'gpt_answer_10', 'gpt_answer_11', 'gpt_answer_12', 'gpt_answer_13',\n",
       "       'gpt_answer_14', 'gpt_answer_15', 'gpt_answer_16', 'gpt_answer_17',\n",
       "       'gpt_answer_18', 'gpt_answer_19', 'gpt_answer_20'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openaitest8.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "openaitest8.drop(['Unnamed: 0'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matheus\\AppData\\Local\\Temp\\ipykernel_84372\\3350579496.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  amelia_answers_gpt[\"openai_model\"] = 1\n"
     ]
    }
   ],
   "source": [
    "amelia_answers_gpt = openaitest8[openaitest8[\"dataset\"]== \"stacked_area_data.csv\"]\n",
    "amelia_answers_gpt[\"openai_model\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matheus\\AppData\\Local\\Temp\\ipykernel_84372\\1813481193.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  amelia_answers_google[\"openai_model\"] = 0\n"
     ]
    }
   ],
   "source": [
    "amelia_answers_google = googletest8[googletest8[\"dataset\"]== \"stacked_area_data.csv\"]\n",
    "amelia_answers_google[\"openai_model\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amelia_answers_google[\"image\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack them together (vertically)\n",
    "amelia_answers = pd.concat([amelia_answers_google, amelia_answers_gpt], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#double checking the image files are the same please god\n",
    "len(amelia_answers[\"image\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merged reference dummies with amelia_answers CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "referenceDummiesWithOldConfigs = pd.read_csv(\"C:/Users/matheus/Desktop/visual_literacy_of_ai_models/referenceDummies_for_test8help.csv\")\n",
    "referenceDummiesWithOldConfigs.drop(['Unnamed: 0.1', 'Unnamed: 0',], axis=1, inplace=True)\n",
    "amelia_reference_dummies =referenceDummiesWithOldConfigs[referenceDummiesWithOldConfigs[\"dataset_stacked_area_data.csv\"] == 1]\n",
    "amelia_answers_reference =pd.merge(amelia_answers, amelia_reference_dummies, \"left\", \"image\")\n",
    "#amelia_answers_reference result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer part stuff\n",
    "import re\n",
    "#lets grab the answers csv\n",
    "ans = pd.read_csv(\"C:/Users/matheus/Desktop/visual_literacy_of_ai_models/ans.csv\")\n",
    "trace2 = ans.iloc[12][\"question\"] #problematic question\n",
    "trace = ans.iloc[40][\"question\"] #problematic question2\n",
    "\n",
    "#define a function to remove these questions from dataframes\n",
    "def filter_dataframe_without_traces_normalized(df, trace1, trace2):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to exclude rows where 'question' matches trace1 or trace2 \n",
    "    (case-insensitive, no spaces) after normalizing the 'question' column.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Compile regular expression for removing spaces\n",
    "        space_re = re.compile(r'\\s+')\n",
    "\n",
    "        # Normalize trace strings\n",
    "        trace1_normalized = space_re.sub('', str(trace1).lower())\n",
    "        trace2_normalized = space_re.sub('', str(trace2).lower())\n",
    "\n",
    "        # Normalize the 'question' column for comparison\n",
    "        normalized_question = df['question'].astype(str).str.lower().apply(lambda x: space_re.sub('', x))\n",
    "\n",
    "        # Apply filtering based on the normalized 'question' column\n",
    "        filtered_df = df[\n",
    "            (normalized_question != trace1_normalized) &\n",
    "            (normalized_question != trace2_normalized)\n",
    "        ]\n",
    "        return filtered_df\n",
    "    except KeyError:\n",
    "        print(\"Error: 'question' column not found in DataFrame.\")\n",
    "        return pd.DataFrame()\n",
    "    except AttributeError:\n",
    "        print(\"Error: one of the traces is not a string or cannot be converted to a string\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droppping the problematic questions from perfect_axes_wdummies\n",
    "amelia_answers_reference_nobadquestions = filter_dataframe_without_traces_normalized(amelia_answers_reference, trace, trace2)\n",
    "#perfect_axes_wdummies_nobadq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking bad questions out of the ans dataset too just in case\n",
    "ans_wo_problematic = ans.drop([12,40])\n",
    "new_ans_for_perfect = ans_wo_problematic.drop(range(43,54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matheus\\AppData\\Local\\Temp\\ipykernel_84372\\2976971451.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  amelia_answers_reference_nobadquestions[\"question_lowered_nospace\"] = amelia_answers_reference_nobadquestions[\"question\"].astype(str).str.lower().str.replace(r'\\s+', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "#now we change the questions to lowercase for perfect matching\n",
    "#now we merge them by question, but we should probably first take out all spaces and highletters from the questions\n",
    "amelia_answers_reference_nobadquestions[\"question_lowered_nospace\"] = amelia_answers_reference_nobadquestions[\"question\"].astype(str).str.lower().str.replace(r'\\s+', '', regex=True)\n",
    "new_ans_for_perfect[\"question_lowered_nospace\"] = new_ans_for_perfect[\"question\"].astype(str).str.lower().str.replace(r'\\s+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we also need to get only the amelia part, cause thats what we are replacing right :)\n",
    "new_ans_for_perfect2 = new_ans_for_perfect[new_ans_for_perfect[\"dataset\"] == \"stacked_area_data.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we merge them\n",
    "amelia_answers_ready_for_count = pd.merge(new_ans_for_perfect2, amelia_answers_reference_nobadquestions, \"left\", \"question_lowered_nospace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "once we have a ready for count, theres two steps, readying the columns and running the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 readying the columns\n",
    "#loop for trimming down all the answers\n",
    "for col in ['gpt_answer_1', 'gpt_answer_2', 'gpt_answer_3',\n",
    "       'gpt_answer_4', 'gpt_answer_5', 'gpt_answer_6', 'gpt_answer_7',\n",
    "       'gpt_answer_8', 'gpt_answer_9', 'gpt_answer_10', 'gpt_answer_11',\n",
    "       'gpt_answer_12', 'gpt_answer_13', 'gpt_answer_14', 'gpt_answer_15',\n",
    "       'gpt_answer_16', 'gpt_answer_17', 'gpt_answer_18', 'gpt_answer_19',\n",
    "       'gpt_answer_20', 'answer']:\n",
    "      if col in amelia_answers_ready_for_count.columns: #Check that the column exists.\n",
    "        amelia_answers_ready_for_count[col] = amelia_answers_ready_for_count[col].astype(str).str.lower().str.replace(r'\\s+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for getting the count of columns that match the correct answer\n",
    "def add_correct_count_column(df, answer_columns, correct_answer_column, new_column_name='correct_count'):\n",
    "    \"\"\"\n",
    "    Adds a new column to the DataFrame containing the number of answer columns that match the correct answer.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to modify.\n",
    "        answer_columns (list): A list of column names representing answer choices.\n",
    "        correct_answer_column (str): The name of the column containing the correct answer.\n",
    "        new_column_name (str): The name of the new column to create. Defaults to 'correct_count'.\n",
    "    \"\"\"\n",
    "\n",
    "    def count_correct(row):\n",
    "        correct_answer = row[correct_answer_column]\n",
    "        correct_count = 0\n",
    "        for col in answer_columns:\n",
    "            if row[col] == correct_answer:\n",
    "                correct_count += 1\n",
    "        return correct_count\n",
    "\n",
    "    df[new_column_name] = df.apply(count_correct, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ill put the omit count as well cause why not\n",
    "#function for getting the count of columns that match the correct answer\n",
    "def add_omission_column(df, answer_columns, new_column_name='omit_count'):\n",
    "    \"\"\"\n",
    "    Adds a new column to the DataFrame containing the number of answer columns that match the correct answer.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to modify.\n",
    "        answer_columns (list): A list of column names representing answer choices.\n",
    "        correct_answer_column (str): The name of the column containing the correct answer.\n",
    "        new_column_name (str): The name of the new column to create. Defaults to 'correct_count'.\n",
    "    \"\"\"\n",
    "\n",
    "    def count_correct(row):\n",
    "        correct_answer = \"omit\"\n",
    "        correct_count = 0\n",
    "        for col in answer_columns:\n",
    "            if row[col] == correct_answer:\n",
    "                correct_count += 1\n",
    "        return correct_count\n",
    "\n",
    "    df[new_column_name] = df.apply(count_correct, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'omit'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amelia_answers_with_correct_count.iloc[130][\"gpt_answer_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we add the correct count\n",
    "amelia_answers_with_correct_count = add_correct_count_column(amelia_answers_ready_for_count, \n",
    "                         ['gpt_answer_1', 'gpt_answer_2', 'gpt_answer_3',\n",
    "       'gpt_answer_4', 'gpt_answer_5', 'gpt_answer_6', 'gpt_answer_7',\n",
    "       'gpt_answer_8', 'gpt_answer_9', 'gpt_answer_10', 'gpt_answer_11',\n",
    "       'gpt_answer_12', 'gpt_answer_13', 'gpt_answer_14', 'gpt_answer_15',\n",
    "       'gpt_answer_16', 'gpt_answer_17', 'gpt_answer_18', 'gpt_answer_19',\n",
    "       'gpt_answer_20'],\"answer\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "amelia_answers_with_correct_count_with_omit_count = add_omission_column(amelia_answers_with_correct_count, ['gpt_answer_1', 'gpt_answer_2', 'gpt_answer_3',\n",
    "       'gpt_answer_4', 'gpt_answer_5', 'gpt_answer_6', 'gpt_answer_7',\n",
    "       'gpt_answer_8', 'gpt_answer_9', 'gpt_answer_10', 'gpt_answer_11',\n",
    "       'gpt_answer_12', 'gpt_answer_13', 'gpt_answer_14', 'gpt_answer_15',\n",
    "       'gpt_answer_16', 'gpt_answer_17', 'gpt_answer_18', 'gpt_answer_19',\n",
    "       'gpt_answer_20'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we remove the question that went wrong, or maybe already fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amelia_answers_with_correct_count_with_omit_count.to_csv(\"amelia_answers_test8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_images_with_csv_bar(df):\n",
    "    \"\"\"\n",
    "    Removes rows where the 'image' column contains the substring '.csv_bar'.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame without matching rows.\n",
    "    \"\"\"\n",
    "    return df[~df[\"image\"].astype(str).str.contains(r'\\.csv_bar', na=False, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_mask(df):\n",
    "    mask = df.apply(lambda col: col.astype(str).str.contains(r'\\.csv_bar', na=False, regex=True)).any(axis=1)\n",
    "    return df[mask] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "amelia_answers_with_correct_count_with_omit_count_fixed = remove_images_with_csv_bar(amelia_answers_with_correct_count_with_omit_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "amelia_answers_with_correct_count_with_omit_count_fixed.to_csv(\"amelia_answers_test8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = return_mask(amelia_answers_with_correct_count_with_omit_count)\n",
    "#df.to_csv(\"mask.csv\") #seems ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10     True\n",
       "90     True\n",
       "170    True\n",
       "250    True\n",
       "330    True\n",
       "410    True\n",
       "490    True\n",
       "570    True\n",
       "650    True\n",
       "730    True\n",
       "Name: plot_type_bar, dtype: bool"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forgot to replace the stuff which is not really bar but stacked bar - it was already done because we used the correct old config!\n",
    "#filter = amelia_answers_with_correct_count_with_omit_count[\"image\"]  == \"stacked_area_data.csv_bar_popular_girls'_names_in_the_uk_black.png\"\n",
    "#amelia_answers_with_correct_count_with_omit_count[filter][\"plot_type_bar\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
